import pandas as pd

configfile: "config/config.yaml"

rule all:
   input:
        expand("calls/{sample}.g.vcf",sample=config["samples"]),
        expand("results/reports/{sample}_1.html",sample=config["samples"]),
        expand("results/reports/{sample}_2.zip",sample=config["samples"]),
        expand("results/reports/{sample}_1.html",sample=config["samples"]),
        expand("results/reports/{sample}_2.zip",sample=config["samples"]),
        expand("results/depth/plots/{sample}.svg",sample=config["samples"])


#Step 1: DESCOMPRESS 
rule descompress:
    input:
        gz1=expand("data/samples/{sample}_1.fastq.gz",sample=config["samples"]),
        gz2=expand("data/samples/{sample}_2.fastq.gz", sample=config["samples"])
    output:
        fq1=expand("data/samples/{sample}_1.fastq",sample=config["samples"]),
        fq2=expand("data/samples/{sample}_2.fastq",sample=config["samples"])
    shell:
        "gunzip -c {input.gz1} > {output.fq1} | gunzip -c {input.gz2} > {output.fq2}"



#Step 2: QUALITY CONTROL
rule quality_control:
    input:
        f1="data/samples/{sample}_1.fastq",
        f2="data/samples/{sample}_2.fastq"
    output:
        html1="results/reports/{sample}_1.html",
        zip1="results/reports/{sample}_1.zip",
        html2="results/reports/{sample}_2.html",
        zip2="results/reports/{sample}_2.zip"
    shell:
        "fastqc {input}"

"""rule fastqc:
    input:
        unpack(get_fastq),
    output:
        html="results/qc/fastqc/{sample}-{unit}.html",
        zip="results/qc/fastqc/{sample}-{unit}.zip",
    log:
        "logs/fastqc/{sample}-{unit}.log",
    shell:
        "0.74.0/bio/fastqc"""   

#Step 3: INDEX GENOME
rule ref_genome:
input:
"data/GCA_904849725_genome.fa"
shell:
"bwa index -a bwtsw {input}"

#Step 4: Mapping

rule map_reads:
    input:
       genome="data/GCA_904849725_genome.fa",
       read1="data/samples/{sample}_1.fastq",
       read2="data/samples/{sample}_2.fastq"
    output:
       temp("results/mapped/{sample}_RG.bam")
    params:
        rg=r"-R '@RG\tID:{sample}\tSM:{sample}\tPL:ILLUMINA'"
    conda:
       "env/mapping.yaml"
    threads: 16
    shell:
       "bwa mem {params.rg} -t {threads} {input.genome} {input.read1} {input.read2} | samtools view -Sb - > {output}"
   
#STEP 5: SORT MAPPED READS

rule sort_bam:
    input:
        "results/mapped/{sample}_RG.bam"
    output:
        "results/sorted/{sample}_sorted.bam"
    conda:
        "env/mapping.yaml"
    shell:
        "samtools sort -o {output} {input}"

#DEPTH CALC

rule depth_calc:
    input:
        "results/sorted/{sample}_sorted.bam"
    output:
        "results/depth/{sample}_depth.csv"
    shell:
        "samtools depth {input} > {output}"

rule plot_depth:
    input:
        "results/depth/{sample}_depth.csv"
    output:
        "results/depth/plots/{sample}.svg"
    script:
        "./scripts/plot-depth.py"        

#STEP 6: Mark duplicates and remove them 
rule mark_duplicates:
    input: 
        "results/sorted/{sample}_sorted.bam"
    output:
        marked_bam="results/markdup/{sample}_nodup.bam",
        metrics="results/markdup/{sample}_nodup.txt"
    shell:
        "java -jar /home/cmiravete/Descargas/picard.jar  MarkDuplicates -I {input} -O {output.marked_bam} -M {output.metrics}"

#STEP 7: INDEXING THE OUTPUT FILE AFTER SORT
#samtools index -c /home/cmiravete/project/snakemake-project/results/markdup/A_1_21_nodup.bam


rule samtools_index:
    input:
        "results/markdup/{sample}_nodup.bam"
    output:
        "results/markdup/{sample}_nodup.bam"
    shell:
        "samtools index -c {input}"

#STEP 8: VARIANT CALLING
rule haplotype_caller:
    input:
        bam="results/markdup/{sample}_nodup.bam",
        ref="/home/cmiravete/project/snakemake-project/data/GCA_904849725_genome.fa"
    output:
        "calls/{sample}.g.vcf"
    shell:
        "/home/cmiravete/Descargas/gatk-4.4.0.0/gatk --java-options  '-Xmx4g'  HaplotypeCaller -R {input.ref} -I {input.bam} -O {output} -ERC GVCF" 

        
